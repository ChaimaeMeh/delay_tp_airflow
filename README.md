# Pipeline ETL GTFS Temps R√©el pour Dashboard Power BI

## Description du projet

Ce projet consiste √† construire un **pipeline ETL** pour traiter des donn√©es de transport en commun en temps r√©el, afin de g√©n√©rer un tableau de bord Power BI permettant de suivre les retards et la qualit√© du service du r√©seau urbain Lignes d‚ÄôAzur (M√©tropole de Nice).  

Les donn√©es utilis√©es proviennent du standard **GTFS** (General Transit Feed Specification) en open data sur [data.gouv.fr](https://www.data.gouv.fr).

Le pipeline extrait les donn√©es, les transforme avec **DuckDB** et les charge au format CSV pour une visualisation interactive sur Power BI Desktop.

---

## Objectifs

- Fournir une vue en temps r√©el des retards.
- G√©n√©rer des KPI pertinents pour la gestion du r√©seau.
- D√©montrer l'orchestration d'un pipeline avec **Apache Airflow**.
- Cr√©er un produit MVP utilisable par les √©quipes op√©rationnelles.

---

## Technologies utilis√©es

- **Python**
- **DuckDB** (traitement OLAP)
- **Pandas**
- **Apache Airflow** (orchestration des t√¢ches ETL)
- **Power BI Desktop** (visualisation des KPI)
- **gtfs-realtime-bindings**
- **Requests**, **PyArrow**
- **Docker**, **Docker Compose**
- **Logging** pour tra√ßabilit√©

---

## Structure du projet

tp-airflow-gtfs-duckdb/
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ requirements.txt
‚îú‚îÄ logs/
‚îú‚îÄ dags/
‚îÇ ‚îú‚îÄ fused_static_realtime.py
‚îÇ ‚îú‚îÄ gtfs_cleanup_dag.py
‚îÇ ‚îú‚îÄ gtfs_realtime_dag.py
‚îÇ ‚îú‚îÄ gtfs_static_dag.py
‚îÇ ‚îî‚îÄ kpi_dag.py
‚îú‚îÄ data/
‚îÇ ‚îî‚îÄ scripts/
‚îÇ ‚îú‚îÄ download_gtfs.py
‚îÇ ‚îú‚îÄ duckdb_utils.py
‚îÇ ‚îú‚îÄ fused_gtfs.py
‚îÇ ‚îú‚îÄ parse_trip_updates.py
‚îÇ ‚îú‚îÄ parse_vehicule_positions.py
‚îÇ ‚îú‚îÄ utils.py
‚îÇ ‚îú‚îÄ validate_data.py
‚îÇ ‚îî‚îÄ kpi/
‚îÇ ‚îú‚îÄ kpi1_avg_delay.py
‚îÇ ‚îú‚îÄ kpi2_bus_map.py
‚îÇ ‚îú‚îÄ ...
‚îÇ ‚îî‚îÄ kpi10_problematic_stops.py
‚îú‚îÄ warehouse/
‚îî‚îÄ exports/


---

## KPI calcul√©s

1. **Retards moyens dans le temps**  
2. **Carte des bus en temps r√©el**  
3. **Carte des arr√™ts avec √©tat de service**  
4. **Lignes les plus en retard**  
5. **Heatmap heures √ó jours**  
6. **Taux de ponctualit√©**  
7. **√âvolution du retard par arr√™t**  
8. **Temps de parcours r√©el vs th√©orique**  
9. **Distribution des retards**  
10. **Top N arr√™ts les plus probl√©matiques**

---

## Architecture du pipeline

Le pipeline suit le sch√©ma ETL :

Extract ‚Üí Transform ‚Üí Load


- **Extract** : r√©cup√©ration des fichiers GTFS statiques et temps r√©el (protocole protobuf).  
- **Transform** : traitement des donn√©es via DuckDB (jointures, agr√©gats, calculs de retards).  
- **Load** : export des r√©sultats horodat√©s au format CSV/Parquet pour Power BI.

üí° L‚Äôorchestration est g√©r√©e par **Apache Airflow** avec plusieurs DAGs pour chaque √©tape.

*(Voir diagramme d‚Äôarchitecture dans `/docs/architecture.png` )*

---

##  Installation

### Pr√©requis

- Python >= 3.9
- Docker (pour Airflow)
- Power BI Desktop

### Installation

1. Cloner le d√©p√¥t :
```bash 
git clone <URL_DU_REPO>
cd tp-airflow-gtfs-duckdb
```

2. Installer les d√©pendances :
pip install -r requirements.txt

3. Lancer Airflow :
docker-compose up -d

4. Acc√©der √† l‚Äôinterface Airflow :
http://localhost:8537

5. Lancer les DAGs :

- gtfs_static_dag

- gtfs_realtime_dag

- kpi_dag

- gtfs_cleanup_dag

### Visualisation dans Power BI

Connecter les fichiers export√©s dans /exports/ √† Power BI Desktop pour cr√©er un tableau de bord interactif avec les KPI d√©finis.

### Nettoyage

Le DAG gtfs_cleanup_dag supprime les fichiers plus anciens que 7 jours dans les dossiers /data et /exports afin d‚Äô√©viter l‚Äôaccumulation excessive de donn√©es.

### Requirements
apache-airflow==2.9.3
pandas
duckdb
pyarrow
requests
gtfs-realtime-bindings
